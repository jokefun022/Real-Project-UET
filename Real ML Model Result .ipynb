{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jokefun022/Real-Project-UET/blob/main/Real%20ML%20Model%20Result%20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 720
        },
        "id": "9f4abe78",
        "outputId": "6873a682-a548-454f-c46d-5a58ca2b39b4"
      },
      "source": [
        "!pip install gensim"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.3.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
            "  Downloading scipy-1.13.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.3.0.post1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open>=1.8.1->gensim) (1.17.3)\n",
            "Downloading gensim-4.3.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.6/26.6 MB\u001b[0m \u001b[31m86.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m92.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.13.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.2/38.2 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, scipy, gensim\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.16.1\n",
            "    Uninstalling scipy-1.16.1:\n",
            "      Successfully uninstalled scipy-1.16.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "tsfresh 0.21.1 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gensim-4.3.3 numpy-1.26.4 scipy-1.13.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "scipy"
                ]
              },
              "id": "3b15851cbe5641e8921d5bbf661f3975"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import KeyedVectors\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "GpAg73fuPmeK"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report, accuracy_score,precision_score, recall_score, f1_score, confusion_matrix\n",
        "import gensim\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Load the dataset\n",
        "tweets = pd.read_csv(\"/content/Complete Data With Emoji.csv\",usecols=['Tweet_Text_With_Emoji',\t'Label',\t'Sentiment Analysis'])\n",
        "\n",
        "# Preprocess the tweets (optional)\n",
        "def preprocess_text(text):\n",
        "    # Apply any text preprocessing steps you want, like lowercasing, stemming, etc.\n",
        "    return text.lower()\n",
        "\n",
        "preprocessed_tweets = [preprocess_text(tweet) for tweet in tweets['Tweet_Text_With_Emoji']]\n",
        "y =tweets['Label']\n",
        "\n",
        "\n",
        "# Vectorize the text data using TF-IDF\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_tfidf = vectorizer.fit_transform(preprocessed_tweets)\n",
        "\n",
        "# Initialize the KFold cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize the Naive Bayes classifier\n",
        "clf = MultinomialNB()\n",
        "\n",
        "# Perform cross-validation\n",
        "accuracy_scores = []\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "f1_scores = []\n",
        "for train_index, test_index in kf.split(X_tfidf):\n",
        "    X_train, X_test = X_tfidf[train_index], X_tfidf[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Train the Naive Bayes classifier\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = clf.predict(X_test)\n",
        "\n",
        "    # Evaluate the model\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    accuracy_scores.append(accuracy)\n",
        "    precision= precision_score(y_test, y_pred,average='weighted')\n",
        "    precision_scores.append(precision)\n",
        "    recall= recall_score(y_test, y_pred,average='weighted')\n",
        "    recall_scores.append(recall)\n",
        "    f1 = f1_score(y_test, y_pred,average='weighted')\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Calculate the average accuracy score\n",
        "avg_accuracy = np.mean(accuracy_scores)\n",
        "print(\"Average accuracy: \", avg_accuracy)\n",
        "avg_precision = np.mean(precision_scores)\n",
        "print(\"Average precision: \", avg_precision)\n",
        "avg_recall = np.mean(recall_scores)\n",
        "print(\"Average recall: \", avg_recall)\n",
        "avg_f1 = np.mean(f1_scores)\n",
        "print(\"Average f1-measure: \", avg_f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "206Uha-ePp7f",
        "outputId": "4fed64f7-b717-4190-bb5c-949e0b37a558"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.99      0.85      1234\n",
            "           1       1.00      0.06      0.12       139\n",
            "           2       0.81      0.66      0.73       611\n",
            "           3       1.00      0.03      0.05        75\n",
            "           4       1.00      0.07      0.12        76\n",
            "\n",
            "    accuracy                           0.77      2135\n",
            "   macro avg       0.91      0.36      0.38      2135\n",
            "weighted avg       0.80      0.77      0.71      2135\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.99      0.85      1238\n",
            "           1       0.92      0.08      0.15       147\n",
            "           2       0.83      0.65      0.72       612\n",
            "           3       1.00      0.01      0.03        69\n",
            "           4       1.00      0.07      0.14        69\n",
            "\n",
            "    accuracy                           0.77      2135\n",
            "   macro avg       0.90      0.36      0.38      2135\n",
            "weighted avg       0.80      0.77      0.72      2135\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      1.00      0.83      1171\n",
            "           1       0.94      0.10      0.18       154\n",
            "           2       0.83      0.59      0.69       654\n",
            "           3       1.00      0.03      0.07        87\n",
            "           4       1.00      0.04      0.08        68\n",
            "\n",
            "    accuracy                           0.74      2134\n",
            "   macro avg       0.90      0.35      0.37      2134\n",
            "weighted avg       0.78      0.74      0.68      2134\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      1.00      0.85      1217\n",
            "           1       1.00      0.09      0.17       143\n",
            "           2       0.84      0.67      0.75       619\n",
            "           3       1.00      0.02      0.05        84\n",
            "           4       1.00      0.11      0.20        71\n",
            "\n",
            "    accuracy                           0.77      2134\n",
            "   macro avg       0.92      0.38      0.40      2134\n",
            "weighted avg       0.81      0.77      0.72      2134\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      1.00      0.84      1195\n",
            "           1       0.81      0.09      0.16       142\n",
            "           2       0.85      0.62      0.72       645\n",
            "           3       0.00      0.00      0.00        83\n",
            "           4       1.00      0.03      0.06        69\n",
            "\n",
            "    accuracy                           0.76      2134\n",
            "   macro avg       0.68      0.35      0.36      2134\n",
            "weighted avg       0.75      0.76      0.70      2134\n",
            "\n",
            "Average accuracy:  0.7602122872901983\n",
            "Average precision:  0.7894208099840279\n",
            "Average recall:  0.7602122872901983\n",
            "Average f1-measure:  0.7086644935348133\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the classifiers\n",
        "logreg = LogisticRegression(max_iter=1000)\n",
        "svm = SVC(kernel='linear')\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "gb = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
        "dt = DecisionTreeClassifier()\n",
        "\n",
        "classifiers = [logreg, svm, rf, gb, dt]\n",
        "for clf in classifiers:\n",
        "    # Perform cross-validation\n",
        "    accuracy_scores = []\n",
        "    precision_scores = []\n",
        "    recall_scores = []\n",
        "    f1_scores = []\n",
        "    for train_index, test_index in kf.split(X_tfidf):\n",
        "        X_train, X_test = X_tfidf[train_index], X_tfidf[test_index]\n",
        "        y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "        # Train the Naive Bayes classifier\n",
        "        clf.fit(X_train, y_train)\n",
        "\n",
        "        # Make predictions\n",
        "        y_pred = clf.predict(X_test)\n",
        "\n",
        "        # Evaluate the model\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        accuracy_scores.append(accuracy)\n",
        "        precision= precision_score(y_test, y_pred,average='weighted')\n",
        "        precision_scores.append(precision)\n",
        "        recall= recall_score(y_test, y_pred,average='weighted')\n",
        "        recall_scores.append(recall)\n",
        "        f1 = f1_score(y_test, y_pred,average='weighted')\n",
        "        f1_scores.append(f1)\n",
        "        print(f'{clf.__class__.__name__} Classification Report: ')\n",
        "        print(classification_report(y_test, y_pred))\n",
        "\n",
        "    # Calculate the average accuracy score\n",
        "    avg_accuracy = np.mean(accuracy_scores)\n",
        "#     print(\"Average accuracy: \", avg_accuracy)\n",
        "    avg_precision = np.mean(precision_scores)\n",
        "#     print(\"Average precision: \", avg_precision)\n",
        "    avg_recall = np.mean(recall_scores)\n",
        "#     print(\"Average recall: \", avg_recall)\n",
        "    avg_f1 = np.mean(f1_scores)\n",
        "#     print(\"Average f1-measure: \", avg_f1)\n",
        "    print(f'{clf.__class__.__name__} accuracy: {avg_accuracy:.4f}, Precision: {avg_precision:.4f},  Recall: {avg_recall:.4f},  f1-score: {avg_f1:.4f}')\n"
      ],
      "metadata": {
        "id": "GXWwk9lUQ9oR",
        "outputId": "f4bc41d1-387a-4ed9-b92e-50937131def1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression Classification Report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.99      0.92      1234\n",
            "           1       0.80      0.47      0.60       139\n",
            "           2       0.94      0.87      0.90       611\n",
            "           3       0.96      0.35      0.51        75\n",
            "           4       0.94      0.41      0.57        76\n",
            "\n",
            "    accuracy                           0.88      2135\n",
            "   macro avg       0.90      0.62      0.70      2135\n",
            "weighted avg       0.89      0.88      0.87      2135\n",
            "\n",
            "LogisticRegression Classification Report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93      1238\n",
            "           1       0.86      0.59      0.70       147\n",
            "           2       0.97      0.88      0.92       612\n",
            "           3       1.00      0.30      0.47        69\n",
            "           4       0.89      0.46      0.61        69\n",
            "\n",
            "    accuracy                           0.90      2135\n",
            "   macro avg       0.92      0.65      0.73      2135\n",
            "weighted avg       0.90      0.90      0.89      2135\n",
            "\n",
            "LogisticRegression Classification Report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      1.00      0.91      1171\n",
            "           1       0.92      0.60      0.73       154\n",
            "           2       0.97      0.84      0.90       654\n",
            "           3       1.00      0.39      0.56        87\n",
            "           4       0.84      0.40      0.54        68\n",
            "\n",
            "    accuracy                           0.88      2134\n",
            "   macro avg       0.91      0.65      0.73      2134\n",
            "weighted avg       0.89      0.88      0.87      2134\n",
            "\n",
            "LogisticRegression Classification Report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93      1217\n",
            "           1       0.82      0.55      0.66       143\n",
            "           2       0.97      0.89      0.93       619\n",
            "           3       1.00      0.35      0.51        84\n",
            "           4       0.94      0.42      0.58        71\n",
            "\n",
            "    accuracy                           0.89      2134\n",
            "   macro avg       0.92      0.64      0.72      2134\n",
            "weighted avg       0.90      0.89      0.88      2134\n",
            "\n",
            "LogisticRegression Classification Report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      1.00      0.93      1195\n",
            "           1       0.87      0.63      0.73       142\n",
            "           2       0.98      0.88      0.93       645\n",
            "           3       0.91      0.47      0.62        83\n",
            "           4       0.92      0.35      0.51        69\n",
            "\n",
            "    accuracy                           0.90      2134\n",
            "   macro avg       0.91      0.67      0.74      2134\n",
            "weighted avg       0.90      0.90      0.89      2134\n",
            "\n",
            "LogisticRegression accuracy: 0.8890, Precision: 0.8959,  Recall: 0.8890,  f1-score: 0.8783\n",
            "SVC Classification Report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      1.00      0.96      1234\n",
            "           1       0.89      0.73      0.81       139\n",
            "           2       0.98      0.92      0.95       611\n",
            "           3       0.92      0.73      0.81        75\n",
            "           4       0.94      0.80      0.87        76\n",
            "\n",
            "    accuracy                           0.94      2135\n",
            "   macro avg       0.93      0.84      0.88      2135\n",
            "weighted avg       0.94      0.94      0.94      2135\n",
            "\n",
            "SVC Classification Report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      1.00      0.97      1238\n",
            "           1       0.86      0.84      0.85       147\n",
            "           2       0.99      0.92      0.95       612\n",
            "           3       0.93      0.59      0.73        69\n",
            "           4       0.89      0.84      0.87        69\n",
            "\n",
            "    accuracy                           0.95      2135\n",
            "   macro avg       0.92      0.84      0.87      2135\n",
            "weighted avg       0.95      0.95      0.95      2135\n",
            "\n",
            "SVC Classification Report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      1.00      0.96      1171\n",
            "           1       0.93      0.83      0.88       154\n",
            "           2       0.99      0.91      0.95       654\n",
            "           3       0.96      0.74      0.83        87\n",
            "           4       0.94      0.87      0.90        68\n",
            "\n",
            "    accuracy                           0.94      2134\n",
            "   macro avg       0.95      0.87      0.90      2134\n",
            "weighted avg       0.95      0.94      0.94      2134\n",
            "\n",
            "SVC Classification Report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      1.00      0.97      1217\n",
            "           1       0.84      0.80      0.82       143\n",
            "           2       0.99      0.92      0.95       619\n",
            "           3       0.98      0.69      0.81        84\n",
            "           4       0.92      0.77      0.84        71\n",
            "\n",
            "    accuracy                           0.94      2134\n",
            "   macro avg       0.93      0.84      0.88      2134\n",
            "weighted avg       0.95      0.94      0.94      2134\n",
            "\n",
            "SVC Classification Report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      1.00      0.97      1195\n",
            "           1       0.91      0.89      0.90       142\n",
            "           2       1.00      0.93      0.96       645\n",
            "           3       0.91      0.82      0.86        83\n",
            "           4       0.92      0.68      0.78        69\n",
            "\n",
            "    accuracy                           0.95      2134\n",
            "   macro avg       0.93      0.86      0.89      2134\n",
            "weighted avg       0.96      0.95      0.95      2134\n",
            "\n",
            "SVC accuracy: 0.9467, Precision: 0.9475,  Recall: 0.9467,  f1-score: 0.9451\n",
            "RandomForestClassifier Classification Report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      1.00      0.97      1234\n",
            "           1       0.95      0.75      0.84       139\n",
            "           2       0.96      0.94      0.95       611\n",
            "           3       0.96      0.68      0.80        75\n",
            "           4       0.98      0.84      0.91        76\n",
            "\n",
            "    accuracy                           0.95      2135\n",
            "   macro avg       0.96      0.84      0.89      2135\n",
            "weighted avg       0.95      0.95      0.94      2135\n",
            "\n",
            "RandomForestClassifier Classification Report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98      1238\n",
            "           1       0.91      0.88      0.90       147\n",
            "           2       0.97      0.94      0.95       612\n",
            "           3       0.96      0.68      0.80        69\n",
            "           4       0.89      0.86      0.87        69\n",
            "\n",
            "    accuracy                           0.96      2135\n",
            "   macro avg       0.94      0.87      0.90      2135\n",
            "weighted avg       0.96      0.96      0.96      2135\n",
            "\n",
            "RandomForestClassifier Classification Report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      1.00      0.97      1171\n",
            "           1       0.93      0.83      0.88       154\n",
            "           2       0.98      0.93      0.95       654\n",
            "           3       0.97      0.75      0.84        87\n",
            "           4       0.90      0.84      0.87        68\n",
            "\n",
            "    accuracy                           0.95      2134\n",
            "   macro avg       0.94      0.87      0.90      2134\n",
            "weighted avg       0.95      0.95      0.95      2134\n",
            "\n",
            "RandomForestClassifier Classification Report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      1.00      0.97      1217\n",
            "           1       0.92      0.86      0.89       143\n",
            "           2       0.98      0.95      0.96       619\n",
            "           3       1.00      0.71      0.83        84\n",
            "           4       0.98      0.83      0.90        71\n",
            "\n",
            "    accuracy                           0.96      2134\n",
            "   macro avg       0.97      0.87      0.91      2134\n",
            "weighted avg       0.96      0.96      0.96      2134\n",
            "\n",
            "RandomForestClassifier Classification Report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98      1195\n",
            "           1       0.91      0.88      0.89       142\n",
            "           2       0.98      0.95      0.96       645\n",
            "           3       0.96      0.80      0.87        83\n",
            "           4       0.97      0.84      0.90        69\n",
            "\n",
            "    accuracy                           0.96      2134\n",
            "   macro avg       0.95      0.89      0.92      2134\n",
            "weighted avg       0.96      0.96      0.96      2134\n",
            "\n",
            "RandomForestClassifier accuracy: 0.9546, Precision: 0.9551,  Recall: 0.9546,  f1-score: 0.9534\n",
            "GradientBoostingClassifier Classification Report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      1.00      0.97      1234\n",
            "           1       0.86      0.83      0.84       139\n",
            "           2       0.99      0.89      0.94       611\n",
            "           3       0.89      0.84      0.86        75\n",
            "           4       0.94      0.95      0.94        76\n",
            "\n",
            "    accuracy                           0.95      2135\n",
            "   macro avg       0.92      0.90      0.91      2135\n",
            "weighted avg       0.95      0.95      0.95      2135\n",
            "\n",
            "GradientBoostingClassifier Classification Report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      1.00      0.98      1238\n",
            "           1       0.88      0.92      0.90       147\n",
            "           2       1.00      0.88      0.93       612\n",
            "           3       0.90      0.90      0.90        69\n",
            "           4       0.88      0.94      0.91        69\n",
            "\n",
            "    accuracy                           0.95      2135\n",
            "   macro avg       0.92      0.93      0.92      2135\n",
            "weighted avg       0.96      0.95      0.95      2135\n",
            "\n",
            "GradientBoostingClassifier Classification Report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      1.00      0.96      1171\n",
            "           1       0.92      0.86      0.89       154\n",
            "           2       1.00      0.86      0.92       654\n",
            "           3       0.90      0.94      0.92        87\n",
            "           4       0.87      0.97      0.92        68\n",
            "\n",
            "    accuracy                           0.94      2134\n",
            "   macro avg       0.92      0.93      0.92      2134\n",
            "weighted avg       0.95      0.94      0.94      2134\n",
            "\n",
            "GradientBoostingClassifier Classification Report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      1.00      0.97      1217\n",
            "           1       0.92      0.88      0.90       143\n",
            "           2       0.99      0.89      0.94       619\n",
            "           3       0.91      0.95      0.93        84\n",
            "           4       0.94      0.90      0.92        71\n",
            "\n",
            "    accuracy                           0.96      2134\n",
            "   macro avg       0.94      0.93      0.93      2134\n",
            "weighted avg       0.96      0.96      0.96      2134\n",
            "\n",
            "GradientBoostingClassifier Classification Report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98      1195\n",
            "           1       0.89      0.89      0.89       142\n",
            "           2       1.00      0.90      0.95       645\n",
            "           3       0.88      0.96      0.92        83\n",
            "           4       0.88      0.88      0.88        69\n",
            "\n",
            "    accuracy                           0.96      2134\n",
            "   macro avg       0.92      0.93      0.92      2134\n",
            "weighted avg       0.96      0.96      0.96      2134\n",
            "\n",
            "GradientBoostingClassifier accuracy: 0.9522, Precision: 0.9540,  Recall: 0.9522,  f1-score: 0.9516\n",
            "DecisionTreeClassifier Classification Report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99      1234\n",
            "           1       0.90      0.87      0.89       139\n",
            "           2       0.96      0.96      0.96       611\n",
            "           3       0.90      0.80      0.85        75\n",
            "           4       0.89      0.93      0.91        76\n",
            "\n",
            "    accuracy                           0.97      2135\n",
            "   macro avg       0.93      0.91      0.92      2135\n",
            "weighted avg       0.97      0.97      0.97      2135\n",
            "\n",
            "DecisionTreeClassifier Classification Report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      1238\n",
            "           1       0.86      0.95      0.91       147\n",
            "           2       0.98      0.96      0.97       612\n",
            "           3       0.90      0.83      0.86        69\n",
            "           4       0.94      0.94      0.94        69\n",
            "\n",
            "    accuracy                           0.98      2135\n",
            "   macro avg       0.94      0.94      0.94      2135\n",
            "weighted avg       0.98      0.98      0.98      2135\n",
            "\n",
            "DecisionTreeClassifier Classification Report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99      1171\n",
            "           1       0.93      0.88      0.91       154\n",
            "           2       0.98      0.96      0.97       654\n",
            "           3       0.93      0.87      0.90        87\n",
            "           4       0.87      0.99      0.92        68\n",
            "\n",
            "    accuracy                           0.97      2134\n",
            "   macro avg       0.94      0.94      0.94      2134\n",
            "weighted avg       0.97      0.97      0.97      2134\n",
            "\n",
            "DecisionTreeClassifier Classification Report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99      1217\n",
            "           1       0.90      0.90      0.90       143\n",
            "           2       0.97      0.97      0.97       619\n",
            "           3       0.88      0.83      0.85        84\n",
            "           4       0.87      0.85      0.86        71\n",
            "\n",
            "    accuracy                           0.97      2134\n",
            "   macro avg       0.92      0.91      0.92      2134\n",
            "weighted avg       0.97      0.97      0.97      2134\n",
            "\n",
            "DecisionTreeClassifier Classification Report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      1195\n",
            "           1       0.93      0.90      0.91       142\n",
            "           2       0.98      0.97      0.98       645\n",
            "           3       0.82      0.90      0.86        83\n",
            "           4       0.93      0.93      0.93        69\n",
            "\n",
            "    accuracy                           0.98      2134\n",
            "   macro avg       0.93      0.94      0.94      2134\n",
            "weighted avg       0.98      0.98      0.98      2134\n",
            "\n",
            "DecisionTreeClassifier accuracy: 0.9740, Precision: 0.9741,  Recall: 0.9740,  f1-score: 0.9739\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#using Word2Vec Technique\n",
        "# Define the classifiers\n",
        "logreg = LogisticRegression(max_iter=1000)\n",
        "svm = SVC(kernel='linear')\n",
        "nb = MultinomialNB()\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "gb = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
        "dt = DecisionTreeClassifier()\n",
        "\n",
        "classifiers = [gb, dt, logreg, svm, rf]\n",
        "\n",
        "sentences = [tweet.split() for tweet in preprocessed_tweets]\n",
        "model = gensim.models.Word2Vec(sentences, min_count=1, vector_size=200)\n",
        "X = []\n",
        "for tweet in sentences:\n",
        "    vec = np.zeros(200)\n",
        "    count = 0\n",
        "    for word in tweet:\n",
        "        try:\n",
        "            vec += model.wv[word]\n",
        "            count += 1\n",
        "        except:\n",
        "            pass\n",
        "    vec /= count\n",
        "    X.append(vec)\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "for clf in classifiers:\n",
        "    # Perform cross-validation\n",
        "    accuracy_scores = []\n",
        "    precision_scores = []\n",
        "    recall_scores = []\n",
        "    f1_scores = []\n",
        "    for train_index, test_index in kf.split(X):\n",
        "        X_train, X_test = np.array(X)[train_index], np.array(X)[test_index]\n",
        "        y_train, y_test = np.array(y)[train_index], np.array(y)[test_index]\n",
        "\n",
        "        # Train the Naive Bayes classifier\n",
        "        clf.fit(X_train, y_train)\n",
        "\n",
        "        # Make predictions\n",
        "        y_pred = clf.predict(X_test)\n",
        "\n",
        "        # Evaluate the model\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        accuracy_scores.append(accuracy)\n",
        "        precision= precision_score(y_test, y_pred,average='weighted')\n",
        "        precision_scores.append(precision)\n",
        "        recall= recall_score(y_test, y_pred,average='weighted')\n",
        "        recall_scores.append(recall)\n",
        "        f1 = f1_score(y_test, y_pred,average='weighted')\n",
        "        f1_scores.append(f1)\n",
        "        print(f'{clf.__class__.__name__} Classification Report: ')\n",
        "        print(classification_report(y_test, y_pred))\n",
        "\n",
        "    # Calculate the average accuracy score\n",
        "    avg_accuracy = np.mean(accuracy_scores)\n",
        "#     print(\"Average accuracy: \", avg_accuracy)\n",
        "    avg_precision = np.mean(precision_scores)\n",
        "#     print(\"Average precision: \", avg_precision)\n",
        "    avg_recall = np.mean(recall_scores)\n",
        "#     print(\"Average recall: \", avg_recall)\n",
        "    avg_f1 = np.mean(f1_scores)\n",
        "#     print(\"Average f1-measure: \", avg_f1)\n",
        "    print(f'{clf.__class__.__name__} accuracy: {avg_accuracy:.4f}, Precision: {avg_precision:.4f},  Recall: {avg_recall:.4f},  f1-score: {avg_f1:.4f}')\n"
      ],
      "metadata": {
        "id": "XcYNO58UR4hs",
        "outputId": "f031c1df-efc1-4cdc-9fdf-a47fdaca53c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GradientBoostingClassifier Classification Report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.89      0.82       606\n",
            "           1       0.73      0.36      0.48        66\n",
            "           2       0.62      0.58      0.60       313\n",
            "           3       0.73      0.20      0.31        40\n",
            "           4       0.75      0.35      0.48        43\n",
            "\n",
            "    accuracy                           0.72      1068\n",
            "   macro avg       0.72      0.48      0.54      1068\n",
            "weighted avg       0.72      0.72      0.70      1068\n",
            "\n",
            "GradientBoostingClassifier Classification Report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.92      0.83       629\n",
            "           1       0.64      0.22      0.33        73\n",
            "           2       0.61      0.55      0.58       298\n",
            "           3       0.78      0.20      0.32        35\n",
            "           4       0.46      0.18      0.26        33\n",
            "\n",
            "    accuracy                           0.72      1068\n",
            "   macro avg       0.65      0.41      0.46      1068\n",
            "weighted avg       0.70      0.72      0.69      1068\n",
            "\n",
            "GradientBoostingClassifier Classification Report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.89      0.83       619\n",
            "           1       0.56      0.30      0.39        76\n",
            "           2       0.62      0.61      0.62       302\n",
            "           3       0.55      0.18      0.27        33\n",
            "           4       0.62      0.22      0.32        37\n",
            "\n",
            "    accuracy                           0.73      1067\n",
            "   macro avg       0.63      0.44      0.49      1067\n",
            "weighted avg       0.71      0.73      0.71      1067\n",
            "\n",
            "GradientBoostingClassifier Classification Report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.92      0.85       618\n",
            "           1       0.67      0.41      0.51        71\n",
            "           2       0.66      0.59      0.62       310\n",
            "           3       0.50      0.08      0.14        36\n",
            "           4       0.59      0.41      0.48        32\n",
            "\n",
            "    accuracy                           0.75      1067\n",
            "   macro avg       0.64      0.48      0.52      1067\n",
            "weighted avg       0.73      0.75      0.73      1067\n",
            "\n",
            "GradientBoostingClassifier Classification Report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.90      0.82       603\n",
            "           1       0.66      0.34      0.45        68\n",
            "           2       0.62      0.56      0.59       319\n",
            "           3       0.55      0.13      0.21        46\n",
            "           4       0.57      0.39      0.46        31\n",
            "\n",
            "    accuracy                           0.71      1067\n",
            "   macro avg       0.63      0.46      0.51      1067\n",
            "weighted avg       0.70      0.71      0.69      1067\n",
            "\n",
            "GradientBoostingClassifier Classification Report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.94      0.83       568\n",
            "           1       0.81      0.34      0.48        86\n",
            "           2       0.69      0.59      0.64       335\n",
            "           3       0.67      0.20      0.30        41\n",
            "           4       0.67      0.27      0.38        37\n",
            "\n",
            "    accuracy                           0.73      1067\n",
            "   macro avg       0.71      0.47      0.53      1067\n",
            "weighted avg       0.73      0.73      0.70      1067\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifiers = [nb]\n",
        "\n",
        "sentences = [tweet.split() for tweet in preprocessed_tweets]\n",
        "model = gensim.models.Word2Vec(sentences, min_count=1, vector_size=200)\n",
        "X = []\n",
        "for tweet in sentences:\n",
        "    vec = np.zeros(200)\n",
        "    count = 0\n",
        "    for word in tweet:\n",
        "        try:\n",
        "            vec += model.wv[word]\n",
        "            count += 1\n",
        "        except:\n",
        "            pass\n",
        "    vec /= count\n",
        "    X.append(vec)\n",
        "X = np.array(X) - np.array(X).min()\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "for clf in classifiers:\n",
        "    # Perform cross-validation\n",
        "    accuracy_scores = []\n",
        "    precision_scores = []\n",
        "    recall_scores = []\n",
        "    f1_scores = []\n",
        "    for train_index, test_index in kf.split(X):\n",
        "        X_train, X_test = np.array(X)[train_index], np.array(X)[test_index]\n",
        "        y_train, y_test = np.array(y)[train_index], np.array(y)[test_index]\n",
        "\n",
        "        # Train the Naive Bayes classifier\n",
        "        clf.fit(X_train, y_train)\n",
        "\n",
        "        # Make predictions\n",
        "        y_pred = clf.predict(X_test)\n",
        "\n",
        "        # Evaluate the model\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        accuracy_scores.append(accuracy)\n",
        "        precision= precision_score(y_test, y_pred,average='weighted')\n",
        "        precision_scores.append(precision)\n",
        "        recall= recall_score(y_test, y_pred,average='weighted')\n",
        "        recall_scores.append(recall)\n",
        "        f1 = f1_score(y_test, y_pred,average='weighted')\n",
        "        f1_scores.append(f1)\n",
        "        print(f'{clf.__class__.__name__} Classification Report: ')\n",
        "        print(classification_report(y_test, y_pred))\n",
        "\n",
        "    # Calculate the average accuracy score\n",
        "    avg_accuracy = np.mean(accuracy_scores)\n",
        "#     print(\"Average accuracy: \", avg_accuracy)\n",
        "    avg_precision = np.mean(precision_scores)\n",
        "#     print(\"Average precision: \", avg_precision)\n",
        "    avg_recall = np.mean(recall_scores)\n",
        "#     print(\"Average recall: \", avg_recall)\n",
        "    avg_f1 = np.mean(f1_scores)\n",
        "#     print(\"Average f1-measure: \", avg_f1)\n",
        "    print(f'{clf.__class__.__name__} accuracy: {avg_accuracy:.4f}, Precision: {avg_precision:.4f},  Recall: {avg_recall:.4f},  f1-score: {avg_f1:.4f}')\n"
      ],
      "metadata": {
        "id": "51dPkyFpf_8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from gensim.models import KeyedVectors\n",
        "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "\n",
        "#using FastText Word Embedding\n",
        "# Load the pre-trained FastText embeddings\n",
        "embedding_path = 'cc.hi.300.vec.gz'\n",
        "embedding_model = KeyedVectors.load_word2vec_format(embedding_path, binary=False)\n",
        "max_length=200\n",
        "\n",
        "\n",
        "# Define the classifiers\n",
        "logreg = LogisticRegression(max_iter=1000)\n",
        "nb = MultinomialNB()\n",
        "svm = SVC(kernel='linear')\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "gb = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "\n",
        "# Generate embeddings for the input texts\n",
        "embedding_size = embedding_model.vector_size\n",
        "input_embeddings = []\n",
        "y = tweets['Label']\n",
        "\n",
        "for text in preprocessed_tweets:\n",
        "    text_embeddings = []\n",
        "    for word in text:\n",
        "        if word in embedding_model.key_to_index:\n",
        "            text_embeddings.append(embedding_model[word])\n",
        "        else:\n",
        "            text_embeddings.append(np.zeros(embedding_size))\n",
        "    input_embeddings.append(text_embeddings)\n",
        "\n",
        "padded_embeddings = pad_sequences(input_embeddings, maxlen=max_length, dtype='float32', padding='post', truncating='post', value=np.zeros(embedding_size))\n",
        "X = padded_embeddings.reshape(padded_embeddings.shape[0], -1)\n",
        "y = np.array(y)\n",
        "classifiers = [logreg, svm, rf, dt, gb]\n",
        "for clf in classifiers:\n",
        "    y_pred = cross_val_predict(clf, X, y, cv=5)\n",
        "    acc = accuracy_score(y, y_pred)\n",
        "    f1 = f1_score(y, y_pred, average='weighted')\n",
        "    prec = precision_score(y, y_pred, average='weighted')\n",
        "    recall = recall_score(y, y_pred, average='weighted')\n",
        "    print(f'{clf.__class__.__name__} accuracy: {acc:.4f}, precision: {prec:.4f}, recall: {recall:.4f},  f1-score: {f1:.4f}')"
      ],
      "metadata": {
        "id": "pdD_jwfkgGI7"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}